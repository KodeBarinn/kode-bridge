use dotenv::dotenv;
use kode_bridge::{ClientConfig, IpcHttpClient, KodeBridgeError, Result};
use serde::{Deserialize, Serialize};
use std::env;
use std::sync::Arc;
use std::time::{Duration, Instant};

#[derive(Debug, Deserialize, Serialize)]
pub struct UpdateProxyPayload {
    pub name: String,
}

/// å¹¶å‘ä»£ç†æµ‹è¯•å’Œå»¶è¿Ÿæµ‹é‡
async fn concurrent_proxy_test(
    client: Arc<IpcHttpClient>,
    proxy_group: &str,
    proxies: Vec<&str>,
) -> Result<()> {
    println!(
        "ğŸš€ Starting concurrent proxy testing for group: {}",
        proxy_group
    );
    println!("ğŸ“Š Testing {} proxies concurrently", proxies.len());

    let start_time = Instant::now();
    let mut tasks = Vec::new();

    // åˆ›å»ºå¹¶å‘ä»»åŠ¡
    for (index, proxy_name) in proxies.iter().enumerate() {
        let client = client.clone();
        let proxy_group = proxy_group.to_string();
        let proxy_name = proxy_name.to_string();

        let task = tokio::spawn(async move {
            let task_start = Instant::now();
            println!("   ğŸ”„ Task {}: Testing proxy '{}'", index + 1, proxy_name);

            // æ‰§è¡Œä»£ç†åˆ‡æ¢æµ‹è¯•
            let result = test_proxy_switch(&client, &proxy_group, &proxy_name).await;
            let duration = task_start.elapsed();

            let success_status = match &result {
                Ok(success) => {
                    if *success {
                        println!(
                            "   âœ… Task {}: Proxy '{}' switched successfully in {:?}",
                            index + 1,
                            proxy_name,
                            duration
                        );
                        "success"
                    } else {
                        println!(
                            "   âš ï¸ Task {}: Proxy '{}' switch failed in {:?}",
                            index + 1,
                            proxy_name,
                            duration
                        );
                        "failed"
                    }
                }
                Err(e) => {
                    println!(
                        "   âŒ Task {}: Proxy '{}' error in {:?}: {}",
                        index + 1,
                        proxy_name,
                        duration,
                        e
                    );
                    "error"
                }
            };

            (index, proxy_name, duration, success_status, result.is_ok())
        });

        tasks.push(task);
    }

    // ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
    let mut results = Vec::new();
    for task in tasks {
        match task.await {
            Ok(result) => results.push(result),
            Err(e) => println!("   âŒ Task join error: {}", e),
        }
    }

    // ç»Ÿè®¡ç»“æœ
    let total_duration = start_time.elapsed();
    let successful_count = results
        .iter()
        .filter(|(_, _, _, status, _)| *status == "success")
        .count();
    let failed_count = results.iter().filter(|(_, _, _, _, ok)| !ok).count();
    let timeout_count = results
        .iter()
        .filter(|(_, _, _, status, _)| *status == "error")
        .count();

    println!();
    println!("ğŸ“Š Concurrent Test Results:");
    println!("   ğŸ¯ Total proxies tested: {}", proxies.len());
    println!("   âœ… Successful switches: {}", successful_count);
    println!("   âŒ Failed requests: {}", failed_count);
    println!("   â° Timeout errors: {}", timeout_count);
    println!("   ğŸ• Total time: {:?}", total_duration);
    println!(
        "   ğŸ“ˆ Average time per request: {:?}",
        Duration::from_millis(total_duration.as_millis() as u64 / proxies.len() as u64)
    );

    // åˆ†æå»¶è¿Ÿåˆ†å¸ƒ
    let mut durations: Vec<Duration> = results
        .iter()
        .map(|(_, _, duration, _, _)| *duration)
        .collect();
    durations.sort();

    if !durations.is_empty() {
        let min_duration = durations.first().unwrap();
        let max_duration = durations.last().unwrap();
        let median_duration = durations[durations.len() / 2];

        println!("   ğŸ“Š Latency Analysis:");
        println!("      âš¡ Fastest: {:?}", min_duration);
        println!("      ğŸŒ Slowest: {:?}", max_duration);
        println!("      ğŸ“Š Median: {:?}", median_duration);
    }

    // å¦‚æœè¶…æ—¶ç‡è¿‡é«˜ï¼Œç»™å‡ºå»ºè®®
    let timeout_rate = timeout_count as f64 / proxies.len() as f64;
    if timeout_rate > 0.3 {
        println!();
        println!(
            "âš ï¸ High timeout rate detected ({:.1}%)",
            timeout_rate * 100.0
        );
        println!("ğŸ’¡ Suggestions:");
        println!(
            "   - Reduce concurrent requests (current: {})",
            proxies.len()
        );
        println!("   - Increase timeout duration");
        println!("   - Check server load and network conditions");
    }

    Ok(())
}

/// æµ‹è¯•å•ä¸ªä»£ç†åˆ‡æ¢
async fn test_proxy_switch(
    client: &IpcHttpClient,
    proxy_group: &str,
    proxy_name: &str,
) -> Result<bool> {
    let path = format!("/proxies/{}", proxy_group);
    let payload = UpdateProxyPayload {
        name: proxy_name.to_string(),
    };

    // æ‰§è¡Œä»£ç†åˆ‡æ¢è¯·æ±‚
    let response = client
        .put(&path)
        .json_body(&serde_json::to_value(&payload)?)
        .timeout(Duration::from_secs(8)) // è®¾ç½®è¾ƒçŸ­çš„è¶…æ—¶
        .send()
        .await?;

    if response.is_success() {
        // éªŒè¯åˆ‡æ¢æ˜¯å¦ç”Ÿæ•ˆ
        tokio::time::sleep(Duration::from_millis(500)).await;
        verify_proxy_switch(client, proxy_group, proxy_name).await
    } else {
        Ok(false)
    }
}

/// éªŒè¯ä»£ç†åˆ‡æ¢æ˜¯å¦ç”Ÿæ•ˆ
async fn verify_proxy_switch(
    client: &IpcHttpClient,
    proxy_group: &str,
    expected_proxy: &str,
) -> Result<bool> {
    let response = client
        .get("/proxies")
        .timeout(Duration::from_secs(5))
        .send()
        .await?;

    if !response.is_success() {
        return Ok(false);
    }

    let proxy_data = response.json_value()?;

    if let Some(proxies_obj) = proxy_data.get("proxies").and_then(|v| v.as_object()) {
        if let Some(group_info) = proxies_obj.get(proxy_group) {
            if let Some(current_proxy) = group_info.get("now").and_then(|v| v.as_str()) {
                return Ok(current_proxy == expected_proxy);
            }
        }
    }

    Ok(false)
}

#[tokio::main]
async fn main() -> Result<()> {
    dotenv().ok();
    println!("ğŸ§ª Concurrent Proxy Testing Example");
    println!("=====================================");

    let ipc_path = env::var("CUSTOM_SOCK").unwrap_or_else(|_| "/tmp/example.sock".to_string());

    // é…ç½®ä¼˜åŒ–çš„HTTPå®¢æˆ·ç«¯
    let config = ClientConfig {
        default_timeout: Duration::from_secs(8),
        enable_pooling: true,
        max_retries: 3,
        retry_delay: Duration::from_millis(100),
        max_concurrent_requests: 8,         // é™åˆ¶å¹¶å‘æ•°
        max_requests_per_second: Some(5.0), // é™åˆ¶è¯·æ±‚é¢‘ç‡
        ..Default::default()
    };

    let client = Arc::new(IpcHttpClient::with_config(&ipc_path, config)?);

    // è·å–å¯ç”¨ä»£ç†
    println!("ğŸ“¡ Fetching available proxies...");
    let response = client
        .get("/proxies")
        .timeout(Duration::from_secs(10))
        .send()
        .await?;

    if !response.is_success() {
        return Err(KodeBridgeError::connection(format!(
            "Failed to get proxies: {}",
            response.status()
        )));
    }

    let proxy_data = response.json_value()?;

    if let Some(proxies_obj) = proxy_data.get("proxies").and_then(|v| v.as_object()) {
        // å¯»æ‰¾ç¬¬ä¸€ä¸ªæœ‰å¤šä¸ªä»£ç†çš„ç»„è¿›è¡Œæµ‹è¯•
        for (group_name, group_info) in proxies_obj.iter() {
            if let Some(all_proxies) = group_info.get("all").and_then(|v| v.as_array()) {
                if all_proxies.len() >= 3 {
                    // è‡³å°‘3ä¸ªä»£ç†æ‰è¿›è¡Œå¹¶å‘æµ‹è¯•
                    let proxy_names: Vec<&str> = all_proxies
                        .iter()
                        .filter_map(|v| v.as_str())
                        .take(8) // é™åˆ¶æœ€å¤š8ä¸ªå¹¶å‘
                        .collect();

                    if !proxy_names.is_empty() {
                        println!(
                            "ğŸ¯ Found group '{}' with {} proxies for testing",
                            group_name,
                            proxy_names.len()
                        );

                        // æ‰§è¡Œå¹¶å‘æµ‹è¯•
                        if let Err(e) =
                            concurrent_proxy_test(client.clone(), group_name, proxy_names).await
                        {
                            println!("âŒ Concurrent test failed: {}", e);
                        }

                        // æ˜¾ç¤ºè¿æ¥æ± ç»Ÿè®¡
                        if let Some(stats) = client.pool_stats() {
                            println!();
                            println!("ğŸ”— Connection Pool Stats: {}", stats);
                        }

                        break;
                    }
                }
            }
        }
    } else {
        println!("âš ï¸ No suitable proxy groups found for testing");
    }

    // æ¸…ç†èµ„æº
    client.close();

    println!();
    println!("ğŸ¯ Concurrent testing completed!");
    println!("ğŸ’¡ Key optimizations applied:");
    println!("   âœ… Connection pooling with increased size (20 connections)");
    println!("   âœ… Reduced timeouts (8s request, 5s connection)");
    println!("   âœ… Enhanced retry logic with exponential backoff");
    println!("   âœ… Concurrent request limiting (8 max)");
    println!("   âœ… Rate limiting (5 requests/sec)");
    println!("   âœ… Jitter in retry delays to prevent thundering herd");

    Ok(())
}
