searchState.loadedDescShard("kode_bridge", 0, "HTTP-style IPC server implementation with routing and …\nStreaming IPC server implementation for real-time data …\nThread-safe buffer pool for reducing memory allocations\nGlobal buffer pools for different use cases\nRAII wrapper for pooled buffers that returns buffer to …\nGet mutable reference to the underlying buffer\nGet the buffer as a byte slice\nGet reference to the underlying buffer\nGet the buffer capacity\nClear the buffer\nExtend buffer with slice\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGet a buffer from the pool or create a new one\nGet appropriate buffer based on expected size with better …\nGet extra large buffer (for very large PUT/POST requests)\nGet large buffer (for big payloads)\nGet medium buffer (for typical HTTP data)\nGet small buffer (for headers, small data)\nGet global buffer pools instance\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCheck if buffer is empty\nGet the buffer length\nCreate a new buffer pool\nPush a single byte\nReserve additional capacity\nGet current pool size for monitoring\nGet pool statistics\nWarm up all pools\nPre-warm the pool with buffers\nClient configuration\nConfiguration builder for fluent configuration setup\nFeature flags for experimental or optional features\nGlobal configuration for kode-bridge\nLogging configuration\nStreaming client configuration\nApply environment variable overrides\nEnable automatic reconnection\nBuffer size for streaming\nBuild the configuration\nEnable request/response caching\nDefault client configuration\nSet client timeout\nConvert client timeout to Duration\nEnable compression\nConvert connection timeout to Duration\nConnection timeout\nDefault timeout for requests\nDefault timeout for streaming connections\nEnable feature\nEnable logging\nEnable or disable connection pooling\nEnable connection pooling by default\nEnable tracing\nFeature flags\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nLoad configuration from a JSON file\nLoad configuration from a TOML file\nEnable HTTP/2 support (future feature)\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCheck if feature is enabled\nEnable connection keep-alive optimization\nLog level (trace, debug, info, warn, error)\nLog connection events\nLog request/response details\nLogging configuration\nSet max retries\nRetry configuration\nMax retries for streaming connections\nEnable metrics collection\nPool configuration\nSet pool configuration\nConvert retry delay to Duration\nRetry delay for streaming connections\nSave configuration to a JSON file\nSave configuration to a TOML file\nStreaming client configuration\nConvert streaming timeout to Duration\nEnable structured logging\nValidate configuration\nLegacy compatibility\nContains the error value\nContains the error value\nSimple string error for backward compatibility\nComprehensive error types for kode-bridge\nContains the success value\nContains the success value\nResult type for kode-bridge operations\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCheck if error is a client error\nCheck if error is retriable\nCheck if error is a server error\nHTTP request builder with fluent interface\nEnhanced HTTP response with rich functionality\nGet response body as bytes\nBuild the HTTP request as bytes with optimized allocation\nGet content length from headers\nGet content type from headers\nReturns the argument unchanged.\nReturns the argument unchanged.\nAdd a custom header\nGet response headers\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCheck if response indicates client error (4xx status)\nCheck if response indicates redirection (3xx status)\nCheck if response indicates server error (5xx status)\nCheck if response indicates success (2xx status)\nParse response body as JSON\nSet JSON body with optimized serialization\nParse response body as generic JSON value\nParse HTTP response from a stream with optimized parsing\nSend HTTP request and parse response\nGet HTTP status code\nGet status code as u16\nGet response body as string\nConvert to legacy Response format for backward …\nGet HTTP version\nConfiguration for IPC HTTP client\nHTTP request builder for fluent API\nEnhanced HTTP response wrapper with chainable methods\nGeneric IPC HTTP client that works on both Unix and …\nGet response body as string\nClose the client and clean up resources\nGet content length from headers\nDefault timeout for requests\nDELETE request\nEnable connection pooling\n设置预期数据大小（用于PUT请求优化）\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGET request\nHEAD request\nAdd custom header\nGet response headers as JSON value (for backward …\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nGet the underlying modern Response\nCheck if response indicates client error (4xx status)\nCheck if response indicates server error (5xx status)\nCheck if response indicates success (2xx status)\nParse response body as JSON\nSet JSON body\nParse response body as generic JSON value\nConcurrent request limit\nRate limiting: max requests per second\nRetry configuration\nCreate a new IPC HTTP client with default configuration\n启用PUT请求专门优化\nOPTIONS request\nPATCH request\nConnection pool configuration\nGet pool statistics (if pooling is enabled)\nPOST request\nPreheat connections for better PUT performance\nPUT request with optimization enabled by default\nOptimized batch PUT operations\nLegacy request method for backward compatibility\nSend the request\nGet the HTTP status code\nSet custom timeout\nConvert to legacy Response format for backward …\nCreate a new IPC HTTP client with custom configuration\nClient connection information\nRequest handler function type\nHTTP response representation\nHigh-level HTTP IPC server\nHTTP request context for handlers\nResponse builder for HTTP responses\nRouter for managing HTTP routes\nConfiguration for HTTP IPC server\nServer statistics\nAdd a route with any HTTP method\nSet response body from bytes\nRequest body as bytes\nBuild the final response\nCreate a new response builder\nClient connection information\nConnection establishment time\nConnection ID for tracking\nAdd a DELETE route\nEnable request/response logging\nCreate an error response\nFind a matching handler and path parameters for the given …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nAdd a GET route\nAdd a header to the response\nRequest headers\nCreate a 500 Internal Server Error response\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCheck if a path is safe\nParse request body as JSON\nSet response body from JSON\nCreate a JSON response\nMaximum number of concurrent connections\nMaximum header size in bytes\nMaximum request body size in bytes\nHTTP method\nCreate a new response builder\nCreate a new router\nCreate a 404 Not Found response\nCreate a simple OK response\nGet path parameters (when using route patterns)\nPath parameters (when using route patterns)\nAdd a POST route\nAdd a PUT route\nGet query parameters from URI\nTimeout for reading requests\nServer shutdown timeout\nSet response status code\nGet request body as UTF-8 string\nSet response body from text\nCreate a text response\nRequest timestamp\nRequest URI\nTimeout for writing responses\nSpecialized IPC streaming client for handling real-time …\nConfiguration for IPC streaming client\nStream request builder for fluent API\nStream response wrapper with chainable methods\nBuffer size for streaming\nCollect all stream content as text\nCollect stream content with timeout\nDefault timeout for connections\nDELETE streaming request\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGET streaming request\nHEAD streaming request\nAdd custom header\nGet headers as JSON for backward compatibility\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nGet the underlying modern StreamingResponse\nCheck if response indicates client error (4xx status)\nCheck if response indicates server error (5xx status)\nCheck if response indicates success (2xx status)\nConvert stream to JSON objects with custom timeout\nSet JSON body\nSend and get JSON results automatically (convenience …\nConvert stream to JSON objects with automatic parsing and …\nMaximum number of retry attempts\nCreate a new IPC streaming client with default …\nOPTIONS streaming request\nPATCH streaming request\nPOST streaming request\nProcess stream with custom JSON processing\nSend and process lines with a handler (convenience method)\nProcess stream in real-time with a handler\nPUT streaming request\nDelay between retry attempts\nSend the streaming request\nGet the HTTP status code\nSet custom timeout\nCreate a new IPC streaming client with custom configuration\nBinary data\nServer shutdown notification\nHigh-level streaming IPC server\nStream from an async iterator\nJSON data message\nSimple JSON data source that generates periodic messages\nKeep-alive ping\nClient connection information for streaming\nMessage types for streaming\nConfiguration for streaming IPC server\nStatistics for the streaming server\nData source trait for streaming servers\nText message\nCurrent active connections\nCreate a binary message\nBroadcast a message to all connected clients\nBroadcast channel capacity\nBuffer size for streaming data\nClean up the source\nUnique client ID\nGet current clients\nConnection establishment time\nEnable connection logging\nClient endpoint information\nNumber of errors for this client\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCheck if the source has more data\nInitialize the source\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCreate a JSON message\nKeep-alive interval for clients\nLast activity time\nLast stats update time\nMaximum number of concurrent connections\nMaximum message size in bytes\nMessages per second (approximate)\nNumber of messages sent to this client\nCreate a new JSON data source with a generator function\nCreate a new iterator source\nCreate a new streaming IPC server\nGet the next batch of messages to send\nStart the server with manual message broadcasting\nStart the server with a data source\nShutdown the server gracefully\nServer shutdown timeout\nServer start time\nGet server statistics\nCreate a text message\nConvert message to bytes for transmission\nTotal connections accepted\nTotal errors\nTotal messages sent\nCreate a new streaming IPC server with custom configuration\nSets the file mode for the Unix domain socket when …\nTimeout for writing to clients\nBuffer pool statistics\nConnection-related metrics\nCPU time tracking\nError tracking metrics\nHealth check system\nLatency tracking with percentiles\nGlobal metrics collection system\nSnapshot of current metrics\nParser cache statistics\nPerformance-related metrics\nRequest-related metrics\nRAII tracker for individual requests\nResource usage metrics\nRetry statistics\nThroughput tracking\nActive connections\nActive requests (in-flight)\nBuffer pool statistics\nCircuit breaker trips\nRecord a connection event\nConnection errors\nRecord connection failure\nConnection establishment times\nConnection metrics\nCPU time tracking\nError tracking\nErrors by type\nFailed connection attempts\nFailed requests\nFailed retries (gave up)\nMark request as failed\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGet global metrics collector\nInitialize metrics system\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nMemory usage estimates\nParser cache statistics\nPerformance metrics\nPool hits (reused connections)\nPool misses (new connections)\nConnection pool utilization\nPrint metrics summary\nRecord an error\nRecord retry attempt\nRequest latency tracking\nRecord a request start\nRequest counters\nRequests by method\nRequests by status code\nResource usage\nRetry counts by attempt number\nRetry statistics\nGet comprehensive metrics snapshot\nMark request as completed successfully\nSuccessful requests\nSuccessful retries (eventual success)\nThroughput tracking\nTimeout errors\nTotal connections created\nTotal errors\nTotal requests processed\nTotal retry attempts\nUpdate resource usage\nCache key for responses\nRAII wrapper that returns parser to cache on drop\nCached response entry\nContains the error value\nType alias for complex HTTP parsing result\nThread-safe HTTP parser cache to avoid repeated allocations\nContains the success value\nSimple LRU response cache\nReusable HTTP parser - simplified version without lifetime …\nClear expired entries\nClear all cached entries\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGet a parser from cache or create new one\nGet cached response if available and not expired\nGet global parser cache\nGet global response cache\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCreate a new parser cache\nCreate a new reusable parser\nParse HTTP request\nParse HTTP request\nParse HTTP response\nParse HTTP response\nStore response in cache\nReset parser state for reuse (no-op in simplified version)\nGet current cache size\nGet cache statistics\nPre-warm the cache\nHigh-performance connection pool for IPC connections\nConfiguration for connection pool\nPool statistics\nA pooled connection wrapper\nGet connection age\nClose all pooled connections\nGet connection timeout as Duration\nMaximum time to wait for a connection from the pool (in …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGet a connection from the pool\nGet multiple connections for concurrent operations\nGet a fresh connection optimized for PUT requests\nGet idle time\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nTake ownership of the underlying stream\nCheck if connection is still valid\nConcurrent request limit\nGet max idle time as Duration\nMaximum time a connection can be idle before being closed …\nRate limiting: max requests per second\nMaximum number of retry attempts\nMaximum number of connections in the pool\nMinimum number of idle connections to maintain\nCreate a new connection pool\nPreheat fresh connections for better PUT performance\nGet retry delay as Duration\nTime to wait between connection attempts (in milliseconds)\nGet pool statistics\nGet the underlying stream\nCreate a connection pool with default configuration\nLegacy response format for backward compatibility\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCircuit breaker pattern for failing services\nUse decorrelated jitter for better distribution\nExponential backoff: delay *= multiplier\nFixed delay between retries\nAdd random jitter up to 50% of delay\nLinear backoff: delay += increment\nNo jitter\nAdd random jitter up to 25% of delay\nAdvanced retry configuration with adaptive strategies\nSmart retry executor\nType alias for complex retry function\nRetry state tracking\nBackoff strategy to use\nSet base delay\nBase delay between retries\nExecute operation with retry logic\nExecute operation with context for better error reporting\nUse exponential backoff strategy\nUse fixed backoff strategy\nConfiguration for large PUT requests\nSmart defaults for different scenarios\nOptimized configuration for PUT requests\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nSet jitter strategy\nJitter strategy to avoid thundering herd\nUse linear backoff strategy\nSet maximum retry attempts\nMaximum number of retry attempts\nSet maximum delay\nMaximum delay between retries (for exponential backoff)\nCreate a new retry configuration\nConvenience function for simple retry operations\nConvenience function with default configuration\nSet custom retry condition\nCustom retry decision function (not cloneable, so we’ll …\nStreaming HTTP response that yields data as it arrives\nCollect all stream data into a string\nCollect stream data with a timeout - optimized for better …\nGet content length from headers\nGet content type from headers\nReturns the argument unchanged.\nGet response headers\nGet headers as JSON value for compatibility\nCalls <code>U::from(self)</code>.\nCheck if response indicates client error (4xx status)\nCheck if response indicates server error (5xx status)\nCheck if response indicates success (2xx status)\nElegant JSON stream processing - automatically parse and …\nParse HTTP response headers and create streaming response\nProcess stream with custom JSON handler\nProcess stream data in real-time with error handling\nProcess stream with timeout and error handling - optimized …\nSend HTTP request and get streaming response\nGet HTTP status code\nGet status code as u16\nConvert to legacy format for compatibility")